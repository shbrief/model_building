---
title: "Build RAVmodel from 8 CRC datasets"
author: "Sehyun Oh"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  BiocStyle::html_document:
    number_sections: no
    toc: yes
    toc_depth: 3
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  comment = "#>", collapse = TRUE, message = FALSE, warning = FALSE 
)
```

```{r}
library(GenomicSuperSignature)
```

# Import
```{r message=FALSE}
dat_dir <- "~/data2/GenomicSuperSignaturePaper/Results/CRC"
load(file.path(dat_dir, "data/eSets/trainingSetNames.RData"))
allStudies <- trainingSetNames

## 8 training datasets
for (study in allStudies) {
    load(file.path(dat_dir, "data/eSets_new", paste0(study, ".RData")))
}
```

# Common Genes
```{r}
allGenes <- vector(mode = "list", length = length(allStudies))
for (i in seq_along(allStudies)) {
    dat <- get(allStudies[i])
    exp <- exprs(dat)
    exp <- rmNaInf(exp)
    allGenes[[i]] <- rownames(exp)
}

## 9242 common genes among 8 training datasets
cg <- Reduce(intersect, allGenes)
```

# PCA
```{r}
trainingDatasets <- "CRC"
n <- 20

## An empty list for PCA results (rotation and variance)
trainingData_PCA <- vector("list", length(allStudies))
names(trainingData_PCA) <- allStudies

##### Calculate sd and mean across all the samples #############################
allSamples <- data.frame(matrix(NA, nrow = length(cg))) 
rownames(allSamples) <- cg
iter <- 0

for (study in allStudies) {
  # dir.path <- file.path(in.dir, study)
  # x <- data.table::fread(file.path(dir.path, paste0(study, "_count.csv")), 
  #                        showProgress = FALSE)
  x <- get(study)
  x <- exprs(x)
  iter <- iter + 1
  allSamples <- cbind(allSamples, x[cg,])
}

allSamples <- allSamples[,-1]
s <- apply(allSamples, 1, sd)
m <- apply(allSamples, 1, mean)
SdMean <- list(sd = s, mean = m)
fname <- paste0(trainingDatasets, "_", iter, "study")

saveRDS(SdMean, paste0(fname, "_SdMean.rds"))   # sd and mean
saveRDS(allSamples, paste0(fname, ".rds")) 

## Remove non-expressing genes in all samples (m == 0)
non_exp <- which(s == 0) %>% names
s <- s[!names(s) %in% non_exp]
m <- m[!names(m) %in% non_exp]
```

```{r}
##### PCA ######################################################################
for (study in allStudies) {
  # dir.path <- file.path(in.dir, study)
  # x <- data.table::fread(file.path(dir.path, paste0(study, "_count.csv")), 
  #                        showProgress = FALSE)
  # x <- data.frame(x[,-1], row.names = x$V1) %>% as.matrix
  x <- get(study)
  x <- exprs(x)
  x <- x[cg,,drop=FALSE]
  
  # Remove non-expressing genes in all samples (m == 0)
  x <- x[!rownames(x) %in% non_exp,]

  # This part will be used if any sample is removed upon filtering
  if (ncol(x) <= 20) {
    print(paste(study, "has only", ncol(x), "samples after filtering."))
    next
  }

  # Normalization
  x <- sweep(x, 1, m)
  x <- sweep(x, 1, s, "/")
  # x <- preprocessCore::normalize.quantiles(x)   # quantile normalization
  
  # PCA
  pca_res <- prcomp(t(x))   # x is a matrix with genes(row) x samples(column)
  trainingData_PCA[[study]]$rotation <- pca_res$rotation[,1:n]
  colnames(trainingData_PCA[[study]]$rotation) <- paste0(study, ".PC", c(1:n))
  eigs <- pca_res$sdev^2
  pca_summary <- rbind(SD = sqrt(eigs),
                       Variance = eigs/sum(eigs),
                       Cumulative = cumsum(eigs)/sum(eigs))
  trainingData_PCA[[study]]$variance <- pca_summary[,1:n]
  colnames(trainingData_PCA[[study]]$variance) <- paste0(study, ".PC", c(1:n))
  
  rm(x)
}

## Save
fname <- paste0(trainingDatasets, "_PCs_rowNorm.rds")
saveRDS(trainingData_PCA, fname)
```


# Clustering
```{r}
library(factoextra)
trainingDatasets <- "CRC"
d <- 4 

## Import input data
fname <- paste0(trainingDatasets, "_PCs_rowNorm.rds")
trainingData_PCA <- readRDS(fname)
print("PCs.rds file is loaded")

## Combine all PCs
allZ_list <- lapply(trainingData_PCA, function(x) x$rotation)
allZ <- Reduce(cbind, allZ_list)
all <- t(allZ)   
print(paste("Dimension of allZ is", dim(allZ)))   # 9.241 genes x 160 PCs
saveRDS(allZ, "allZ.rds")

##### Hierarchical Clustering ##################################################
## Calculate distance
start <- Sys.time()
res.dist <- factoextra::get_dist(all, method = "spearman")
end <- Sys.time()
t <- end - start
print(t)  
saveRDS(res.dist, "res_dist.rds")

## Cut the tree
k <- round(nrow(all)/d, 0)
start <- Sys.time()
res.hcut <- factoextra::hcut(res.dist, k = k, hc_func = "hclust", 
                             hc_method = "ward.D", hc_metric = "spearman")
end <- Sys.time()
t2 <- end - start
print(t2)   
saveRDS(res.hcut, file.path(out_dir, "res_hcut.rds"))


##### Build avgLoading #########################################################
trainingData_PCclusters <- buildAvgLoading(allZ, k, cluster = res.hcut$cluster)

## Silhouette Width
cl <- trainingData_PCclusters$cluster
silh_res <- cluster::silhouette(cl, res.dist)
cl_silh_width <- summary(silh_res)$clus.avg.widths
trainingData_PCclusters$sw <- cl_silh_width  # add silhouette width to the result

## Save
fname <- paste0(trainingDatasets, "_PCclusters.rds")
saveRDS(trainingData_PCclusters, fname)
```

# Final Model