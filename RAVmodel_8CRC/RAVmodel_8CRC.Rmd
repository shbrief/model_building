---
title: "Build RAVmodel from 8 CRC datasets"
author: "Sehyun Oh"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  BiocStyle::html_document:
    number_sections: no
    toc: yes
    toc_depth: 3
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  comment = "#>", collapse = TRUE, message = FALSE, warning = FALSE, eval=FALSE 
)
```

```{r message=FALSE, eval=TRUE}
library(GenomicSuperSignature)
library(dplyr)
library(factoextra)
```

# Parameters
Model specific parameters 
```{r}
trainingDatasets <- "CRC"
n <- 20   # PCA: the number of top PCs to collect
d <- 4    # clustering
note <- "8 CRC training datasets using 9,242 common genes"
```

# Import
```{r message=FALSE}
dat_dir <- "~/data2/GenomicSuperSignaturePaper/Results/CRC"
load(file.path(dat_dir, "data/eSets/trainingSetNames.RData"))
allStudies <- trainingSetNames

## 8 training datasets
for (study in allStudies) {
    load(file.path(dat_dir, "data/eSets_new", paste0(study, ".RData")))
}
```


# Common Genes
```{r}
allGenes <- vector(mode = "list", length = length(allStudies))
for (i in seq_along(allStudies)) {
    dat <- get(allStudies[i])
    exp <- exprs(dat)
    exp <- rmNaInf(exp)
    allGenes[[i]] <- rownames(exp)
}

## 9242 common genes among 8 training datasets
cg <- Reduce(intersect, allGenes)
```

# PCA
```{r}
## An empty list for PCA results (rotation and variance)
trainingData_PCA <- vector("list", length(allStudies))
names(trainingData_PCA) <- allStudies

##### Calculate sd and mean across all the samples #############################
allSamples <- data.frame(matrix(NA, nrow = length(cg))) 
rownames(allSamples) <- cg
iter <- 0

for (study in allStudies) {
  # dir.path <- file.path(in.dir, study)
  # x <- data.table::fread(file.path(dir.path, paste0(study, "_count.csv")), 
  #                        showProgress = FALSE)
  x <- get(study)
  x <- exprs(x)
  iter <- iter + 1
  allSamples <- cbind(allSamples, x[cg,])
}

allSamples <- allSamples[,-1]
s <- apply(allSamples, 1, sd)
m <- apply(allSamples, 1, mean)
SdMean <- list(sd = s, mean = m)
fname <- paste0(trainingDatasets, "_", iter, "study")

saveRDS(SdMean, paste0(fname, "_SdMean.rds"))   # sd and mean
saveRDS(allSamples, paste0(fname, ".rds")) 

## Remove non-expressing genes in all samples (m == 0)
non_exp <- which(s == 0) %>% names
s <- s[!names(s) %in% non_exp]
m <- m[!names(m) %in% non_exp]
```

```{r}
##### PCA ######################################################################
for (study in allStudies) {
  # dir.path <- file.path(in.dir, study)
  # x <- data.table::fread(file.path(dir.path, paste0(study, "_count.csv")), 
  #                        showProgress = FALSE)
  # x <- data.frame(x[,-1], row.names = x$V1) %>% as.matrix
  x <- get(study)
  x <- exprs(x)
  x <- x[cg,,drop=FALSE]
  
  # Remove non-expressing genes in all samples (m == 0)
  x <- x[!rownames(x) %in% non_exp,]

  # This part will be used if any sample is removed upon filtering
  if (ncol(x) <= 20) {
    print(paste(study, "has only", ncol(x), "samples after filtering."))
    next
  }

  # Normalization
  x <- sweep(x, 1, m)
  x <- sweep(x, 1, s, "/")
  # x <- preprocessCore::normalize.quantiles(x)   # quantile normalization
  
  # PCA
  pca_res <- prcomp(t(x))   # x is a matrix with genes(row) x samples(column)
  trainingData_PCA[[study]]$rotation <- pca_res$rotation[,1:n]
  colnames(trainingData_PCA[[study]]$rotation) <- paste0(study, ".PC", c(1:n))
  eigs <- pca_res$sdev^2
  pca_summary <- rbind(SD = sqrt(eigs),
                       Variance = eigs/sum(eigs),
                       Cumulative = cumsum(eigs)/sum(eigs))
  trainingData_PCA[[study]]$variance <- pca_summary[,1:n]
  colnames(trainingData_PCA[[study]]$variance) <- paste0(study, ".PC", c(1:n))
  
  rm(x)
}

## Save
fname <- paste0(trainingDatasets, "_PCs_rowNorm.rds")
saveRDS(trainingData_PCA, fname)
```

# Clustering
```{r}
## Import input data
fname <- paste0(trainingDatasets, "_PCs_rowNorm.rds")
trainingData_PCA <- readRDS(fname)
print("PCs.rds file is loaded")

## Combine all PCs
allZ_list <- lapply(trainingData_PCA, function(x) x$rotation)
allZ <- Reduce(cbind, allZ_list)
all <- t(allZ)   
print(paste("Dimension of allZ is", dim(allZ)))   # 9.241 genes x 160 PCs
saveRDS(allZ, "allZ.rds")

##### Hierarchical Clustering ##################################################
## Calculate distance
start <- Sys.time()
res.dist <- factoextra::get_dist(all, method = "spearman")
end <- Sys.time()
t <- end - start
print(t)  
saveRDS(res.dist, "res_dist.rds")

## Cut the tree
k <- round(nrow(all)/d, 0)
start <- Sys.time()
res.hcut <- factoextra::hcut(res.dist, k = k, hc_func = "hclust", 
                             hc_method = "ward.D", hc_metric = "spearman")
end <- Sys.time()
t2 <- end - start
print(t2)   
saveRDS(res.hcut, "res_hcut.rds")

##### Build avgLoading #########################################################
trainingData_PCclusters <- buildAvgLoading(allZ, k, cluster = res.hcut$cluster)

## Silhouette Width
cl <- trainingData_PCclusters$cluster
silh_res <- cluster::silhouette(cl, res.dist)
cl_silh_width <- summary(silh_res)$clus.avg.widths
trainingData_PCclusters$sw <- cl_silh_width  # add silhouette width to the result

## Save
fname <- paste0(trainingDatasets, "_PCclusters.rds")
saveRDS(trainingData_PCclusters, fname)
```

# Final Model
```{r}
## Load PCA and Clustering results
trainingData_PCA <- readRDS(paste0(trainingDatasets, "_PCs_rowNorm.rds"))  # PCA result
fname <- paste0(trainingDatasets, "_PCclusters.rds")
trainingData_PCclusters <- readRDS(fname)  # Clustering result
```

```{r}
##### Variance Explained from PCA result #######################################
pca_summary <- list()
for (i in seq_along(trainingData_PCA)) {
    pca_summary[[i]] <- trainingData_PCA[[i]]$variance
    names(pca_summary)[i] <- names(trainingData_PCA)[i]
}

##### MeSH terms ###############################################################
# dir <- system.file("extdata", package = "GenomicSuperSignaturePaper")
# load(file.path(dir, "MeSH_terms_1399refinebio.rda"))
# x <- mesh_table
# 
# # Update bagOfWords and MeSH_freq
# MeSH_freq <- table(x$name) %>% sort(., decreasing = TRUE)  # freq. of each term
# for (i in 1:nrow(x)) {x$bagOfWords[i] <- MeSH_freq[x$name[i]]}  # add freq. to the main table
# 
# # 1398 studies in the given table
# unique_id <- unique(x$identifier)
# 
# # Split MeSH term table to a list of each study, `all_MeSH`
# # RAVmodel is currently doesn't have 'concept'.
# all_MeSH <- vector("list", length(unique_id))
# names(all_MeSH) <- unique_id
# for (study in unique_id) {
#     ind <- grepl(study, x$identifier)
#     all_MeSH[[study]] <- x[ind, c("score", "identifier", "concept", "name", 
#                                   "explanation", "bagOfWords")]
# }
# 
# # Subset only to the studies used in the model 
# trainingData_MeSH <- all_MeSH[allStudies]




##### Build PCAGenomicSignatures object ########################################
RAVmodel <- PCAGenomicSignatures(assays = list(RAVindex = as.matrix(trainingData_PCclusters$avgLoading)))
metadata(RAVmodel) <- trainingData_PCclusters[c("cluster", "size", "k", "n")]
names(metadata(RAVmodel)$size) <- paste0("RAV", seq_len(ncol(RAVmodel)))
geneSets(RAVmodel) <- annot_database
studies(RAVmodel) <- trainingData_PCclusters$studies
silhouetteWidth(RAVmodel) <- trainingData_PCclusters$sw
# metadata(RAVmodel)$MeSH_freq <- MeSH_freq
trainingData(RAVmodel)$PCAsummary <- pca_summary[rownames(trainingData(RAVmodel))]
# mesh(RAVmodel) <- trainingData_MeSH[rownames(trainingData(RAVmodel))]
updateNote(RAVmodel) <- note
metadata(RAVmodel)$version <- "1.1.0"

## Save pre-GSEA version
fname <- paste0(trainingDatasets, "_RAVmodel_", 
                format(Sys.Date(), format="%Y%m%d"), ".rds")
saveRDS(RAVmodel, fname)


##### GSEA #####################################################################
dir2 <- system.file("scripts", package = "GenomicSuperSignature")
gsea_script <- file.path(dir2, "build_gsea_DB.R")
source(gsea_script)  # This is the processing script. Doule-check the details.

searchPathways_func <- file.path(dir2, "searchPathways.R")
source(searchPathways_func)  # load the function

gsea_dir <- paste0("gsea_", annotGeneSets)  # GSEA C2 DB is saved here
gsea_all <- searchPathways(RAVmodel, gsea_dir)  
gsea(RAVmodel) <- gsea_all

## Save post-GSEA version
fname <- paste0(trainingDatasets, "_RAVmodel_", annotGeneSets, 
                "_", format(Sys.Date(), format="%Y%m%d"),".rds")
saveRDS(RAVmodel, fname)
```



# Validation
```{r}

```

